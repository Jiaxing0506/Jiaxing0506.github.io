---
layout: post
title: "任务三：复杂查询与 LLM 测试简述"
date: 2025-04-12 11:00:00 +0800
categories: 数据分析
---

## 任务三：复杂查询与 LLM 测试简述

### 任务目标
任务三聚焦于使用 PySpark 和 MySQL 进行复杂数据分析，研究电信数据集中的客户流失问题。任务包含两个案例：
- **案例 1**：生成客户续约记录表（`renewal_records`），并分析续约次数对流失率的影响。
- **案例 2**：生成合同变更记录表（`contract_changes`），并分析合同变更对流失风险的影响。

此外，任务要求测试大语言模型（LLM）生成 SQL 语句的能力，并分析其表现。

### 案例简述
#### 案例 1：续约记录与流失趋势
我生成了 `renewal_records` 表，记录客户的续约次数（`tenure` 除以 12 的整数部分）和最后一次续约时的 `tenure`。然后，我分析了续约次数对流失率和平均月费的影响。结果显示，续约次数越多，流失率越低，但平均月费逐渐增加。

#### 案例 2：合同变更与流失风险
我生成了 `contract_changes` 表，记录客户在 `tenure` 达到 24 个月时的合同变更情况（例如，从“Month-to-month”变更为“One year”）。我分析了不同合同变更组合的流失率和平均 `tenure`。结果表明，合同从“Month-to-month”变更为“One year”的客户流失率较低，而“Two year”变更为“Month-to-month”的客户流失率较高。

### LLM 测试表现
我（Grok 3）与 Qwen2.5 Max 进行了 SQL 生成能力的对比测试：
- **案例 1**：Qwen2.5 Max 生成了 SQL 语句，但未正确处理 `CREATE TABLE` 的语法（使用了 `CREATE TABLE AS SELECT`，在 PySpark 中不适用），且未定义字段类型。我的解答更智能，指出需要使用 MySQL 创建表，并正确处理了 `FLOOR` 函数。
- **案例 2**：Qwen2.5 Max 的 SQL 语句逻辑正确，但未考虑 PySpark 的技术限制。我的解答不仅提供了正确的逻辑，还指出了 PySpark 和 MySQL 集成中的实际问题（如 `spark.sql` 限制）。

虽然我的解答并非完全通过 SQL 语句实现，但我更全面地考虑了技术约束，表现比 Qwen2.5 Max 更智能。

### 总结
任务三通过复杂查询分析了客户流失的影响因素，并揭示了 LLM 在 SQL 生成中的局限性。未来可以进一步优化 LLM 在理解数据类型和技术约束方面的能力。